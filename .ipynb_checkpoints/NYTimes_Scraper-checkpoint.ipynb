{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "590c9896",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "45885cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NYTimesScraper:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.date_pattern = r\"/(\\d{4}/\\d{2}/\\d{2})/\"\n",
    "        self.money_pattern = r'(\\$\\d+(\\.\\d+)?|\\$\\d{1,3}(,\\d{3})*(\\.\\d+)?|\\d+(\\.\\d+)? (dollars|USD))'\n",
    "        self.df = pd.DataFrame()\n",
    "\n",
    "        \n",
    "    def subtract_months_from_current_date(self):\n",
    "        current_date = datetime.now()\n",
    "        new_date = current_date - relativedelta(months=self.config['num_months'])\n",
    "        return new_date\n",
    "\n",
    "    \n",
    "    def start_browser(self):\n",
    "        path = \"chromedriver\"\n",
    "        service = Service(path)\n",
    "        return webdriver.Chrome(service=service)\n",
    "\n",
    "    \n",
    "    def navigate_to_site(self, driver, url):\n",
    "        driver.get(url)\n",
    "\n",
    "        \n",
    "    def close_overlay(self, driver):\n",
    "        try:\n",
    "            overlay = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//div[@id=\"complianceOverlay\"]/div[@class=\"css-hqisq1\"]/button[@class=\"css-1fzhd9j\"]')))\n",
    "            overlay.click()\n",
    "        except Exception as e:\n",
    "            print(\"Error while closing overlay:\", e)\n",
    "\n",
    "            \n",
    "    def enter_search_phrase(self, driver):\n",
    "        try:\n",
    "            driver.find_element(by='xpath', value='//div[@class=\"css-10488qs\"]/button[@class=\"css-tkwi90 e1iflr850\"]').click()\n",
    "            search_box = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//div[@id=\"search-input\"]/form[@action=\"/search\"]/div[@class=\"css-1jl66k3\"]/input[@data-testid=\"search-input\"]')))\n",
    "            search_box.send_keys(self.config['search_phrase'])\n",
    "            search_box.send_keys(Keys.RETURN)\n",
    "        except NoSuchElementException as e:\n",
    "            print(\"Error: Search box not found. Check if the website structure has changed.\", e)\n",
    "\n",
    "            \n",
    "    def apply_filters(self, driver):\n",
    "        try:\n",
    "            # Wait for the sections to be present and click on the search-multiselect-button\n",
    "            sections = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//button[@data-testid=\"search-multiselect-button\"]')))\n",
    "            sections.click()\n",
    "\n",
    "            # Wait for the categories to be present and select the desired news_categories\n",
    "            categories = driver.find_elements(by='xpath', value='//div[@class=\"css-tw4vmx\"]/ul[@data-testid=\"multi-select-dropdown-list\"]/li[@class=\"css-1qtb2wd\"]/label[@class=\"css-1a8ayg6\"]/span[@class=\"css-16eo56s\"]')\n",
    "            for cat in categories:\n",
    "                # Use JavaScript to get the direct text content of the span element\n",
    "                category_text = driver.execute_script('return arguments[0].firstChild.textContent', cat)\n",
    "                if category_text in self.config['news_category']:\n",
    "                    cat.click()\n",
    "\n",
    "            # Wait for the sorting dropdown to be present and click on it\n",
    "            news_sorting = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//div[@class=\"css-hrdzfd\"]')))\n",
    "            news_sorting.click()\n",
    "\n",
    "            # Now, select the 'newest' option from the sorting dropdown\n",
    "            newest_option = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//select[@class=\"css-v7it2b\"]/option[@value=\"newest\"]')))\n",
    "            newest_option.click()\n",
    "            time.sleep(5)\n",
    "        except Exception as e:\n",
    "            print(\"Error while applying filters:\", e)\n",
    "\n",
    "            \n",
    "    def extract_data(self, driver, end_date):\n",
    "        try:\n",
    "            # Wait for the search results to be present\n",
    "            search_results = WebDriverWait(driver, 10).until(EC.presence_of_all_elements_located((By.XPATH, '//main[@id=\"site-content\"]/div[@class=\"css-1wa7u5r\"]/div/div[@class=\"css-46b038\"]/ol[@data-testid=\"search-results\"]')))\n",
    "            articles = search_results[0].find_elements(by='xpath', value='//li[@class=\"css-1l4w6pd\"]/div[@class=\"css-1kl114x\"]')\n",
    "\n",
    "            dates = []\n",
    "            titles = []\n",
    "            descriptions = []\n",
    "            img_srcs = []\n",
    "            for article in articles:\n",
    "                url = article.find_element(by='xpath', value='.//div[@class=\"css-1i8vfl5\"]/div[@class=\"css-e1lvw9\"]/a').get_attribute(\"href\")\n",
    "\n",
    "                # Search for the date pattern in the URL and extract the date\n",
    "                match = re.search(self.date_pattern, url)\n",
    "                if match:\n",
    "                    # Extracted date as string (e.g., \"2023/07/22\")\n",
    "                    extracted_date_str = match.group(1)\n",
    "                    # Convert the extracted date string into a datetime object\n",
    "                    extracted_date = datetime.strptime(extracted_date_str, \"%Y/%m/%d\")\n",
    "\n",
    "                    # Extract the title\n",
    "                    title = article.find_element(by='xpath', value='.//div[@class=\"css-1i8vfl5\"]/div[@class=\"css-e1lvw9\"]/a/h4[@class=\"css-2fgx4k\"]').text\n",
    "\n",
    "                    # Extract the description if available\n",
    "                    try:\n",
    "                        description = article.find_element(by='xpath', value='.//div[@class=\"css-1i8vfl5\"]/div[@class=\"css-e1lvw9\"]/a/p[@class=\"css-16nhkrn\"]').text\n",
    "                    except NoSuchElementException:\n",
    "                        description = \"\"\n",
    "\n",
    "                    # Extract the image source\n",
    "                    img_url = article.find_element(by='xpath', value='.//div[@class=\"css-1i8vfl5\"]/figure[@class=\"css-tap2ym\"]/div/img').get_attribute(\"src\")\n",
    "                    img_src = img_url[img_url.find('https://'):img_url.find('.jpg') + 4]\n",
    "\n",
    "                    dates.append(extracted_date)\n",
    "                    titles.append(title)\n",
    "                    descriptions.append(description)\n",
    "                    img_srcs.append(img_src)\n",
    "\n",
    "            if len(dates) > 0:\n",
    "                temp_df = pd.DataFrame({\n",
    "                    \"dates\": dates,\n",
    "                    \"titles\": titles,\n",
    "                    \"descriptions\": descriptions,\n",
    "                    \"img_sources\": img_srcs\n",
    "                })\n",
    "                self.df = pd.concat([self.df, temp_df], ignore_index=True)\n",
    "                self.df = self.df.drop_duplicates()\n",
    "            time.sleep(5)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(\"Error while extracting data:\", e)\n",
    "\n",
    "            \n",
    "    def show_more(self, driver):\n",
    "        try:\n",
    "            driver.find_element(by='xpath', value='//main[@id=\"site-content\"]/div[@class=\"css-1wa7u5r\"]/div/div[@class=\"css-1t62hi8\"]/div[@class=\"css-vsuiox\"]/button').click()\n",
    "        except NoSuchElementException:\n",
    "            pass\n",
    "\n",
    "        \n",
    "    def download_image(self, img_url):\n",
    "        try:\n",
    "            # Create a new folder named \"downloaded_imgs\" if it doesn't exist\n",
    "            if not os.path.exists(\"downloaded_imgs\"):\n",
    "                os.makedirs(\"downloaded_imgs\")\n",
    "                \n",
    "            response = requests.get(img_url, stream=True)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            # Get the filename from the URL (assumes the URL ends with .jpg or .png, adjust if necessary)\n",
    "            file_name = img_url.split(\"/\")[-1]\n",
    "\n",
    "            # Combine the new folder path and filename\n",
    "            file_path = os.path.join(\"downloaded_imgs\", file_name)\n",
    "\n",
    "            with open(file_path, 'wb') as file:\n",
    "                for chunk in response.iter_content(chunk_size=8192):\n",
    "                    file.write(chunk)\n",
    "\n",
    "            return file_path\n",
    "        except Exception as e:\n",
    "            print(\"Error while downloading image:\", e)\n",
    "            return None\n",
    "\n",
    "        \n",
    "    def contains_money(self, text):\n",
    "        if text:\n",
    "            return bool(re.search(self.money_pattern, text))\n",
    "        return False\n",
    "\n",
    "    \n",
    "    def process_data(self):\n",
    "        self.df['contains_money'] = self.df['titles'].str.cat(self.df['descriptions'], sep=' ').apply(self.contains_money)\n",
    "        self.df['count_search_phrase'] = (self.df['titles'].str.contains(self.config['search_phrase'], case=False).astype(int) +\n",
    "                                          self.df['descriptions'].str.contains(self.config['search_phrase'], case=False).astype(int))\n",
    "\n",
    "    def save_to_excel(self):\n",
    "        self.df.to_excel(\"nytimes_data.xlsx\", index=False)\n",
    "\n",
    "        \n",
    "    def run(self):\n",
    "        try:\n",
    "            driver = self.start_browser()\n",
    "            self.navigate_to_site(driver, \"https://www.nytimes.com/\")\n",
    "            self.close_overlay(driver)\n",
    "            self.enter_search_phrase(driver)\n",
    "            self.apply_filters(driver)\n",
    "            \n",
    "            end_date = self.subtract_months_from_current_date()\n",
    "            self.extract_data(driver, end_date)\n",
    "            \n",
    "            while self.df.shape[0] > 0 and self.df['dates'].min() >= end_date:\n",
    "                self.show_more(driver)\n",
    "                time.sleep(5)\n",
    "                self.extract_data(driver, end_date)\n",
    "\n",
    "            driver.quit()\n",
    "            if self.df.shape[0] > 0:\n",
    "                self.process_data()\n",
    "                self.save_to_excel()\n",
    "\n",
    "            for img_url in self.df[\"img_sources\"].values:\n",
    "                self.download_image(img_url)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(\"Error during execution:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f17c83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Read JSON data from the file\n",
    "    with open(\"config.json\", \"r\") as file:\n",
    "        config_data = json.load(file)\n",
    "\n",
    "    scraper = NYTimesScraper(config_data)\n",
    "    scraper.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84da58f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
